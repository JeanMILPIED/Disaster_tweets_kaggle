{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step1: import the proper packages to the notebook environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages we may need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import re\n",
    "\n",
    "# Set seed for reproducibility\n",
    "import random; random.seed(53)\n",
    "\n",
    "#import some specific NPL packages\n",
    "import nltk\n",
    "\n",
    "# Import all we need from sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step2: load the test and train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=pd.read_csv('./train.csv')\n",
    "data_test=pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step3: descriptive exploration of the 2 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract the main features\n",
    "def data_set_exploration(dataset):\n",
    "    print(dataset.shape)\n",
    "    print(dataset.columns)\n",
    "    print('\\n')\n",
    "    print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 5)\n",
      "Index(['id', 'keyword', 'location', 'text', 'target'], dtype='object')\n",
      "\n",
      "\n",
      "id             0\n",
      "keyword       61\n",
      "location    2533\n",
      "text           0\n",
      "target         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_set_exploration(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are 7613 tweets in the train database with 61 keyword missing and 2533 location missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3263, 4)\n",
      "Index(['id', 'keyword', 'location', 'text'], dtype='object')\n",
      "\n",
      "\n",
      "id             0\n",
      "keyword       26\n",
      "location    1105\n",
      "text           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_set_exploration(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are 3263 tweets in the test database with 26 keyword missing and 1103 location missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the ratio of missing data in the 2 datasets are roughly the same: good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a function that fill missing values with most present value\n",
    "def my_fill_na_function(dataset):\n",
    "    for my_column in dataset.columns:\n",
    "        max_value= dataset[my_column].value_counts().index[0]\n",
    "        dataset[my_column]=dataset[my_column].fillna(max_value)\n",
    "        print('the max_value of column %s is %s' %(my_column,max_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the max_value of column id is 10235\n",
      "the max_value of column keyword is deluged\n",
      "the max_value of column location is New York\n",
      "the max_value of column text is 11-Year-Old Boy Charged With Manslaughter of Toddler: Report: An 11-year-old boy has been charged with manslaughter over the fatal sh...\n"
     ]
    }
   ],
   "source": [
    "my_fill_na_function(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "keyword     0\n",
       "location    0\n",
       "text        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the max_value of column id is 2047\n",
      "the max_value of column keyword is fatalities\n",
      "the max_value of column location is USA\n",
      "the max_value of column text is 11-Year-Old Boy Charged With Manslaughter of Toddler: Report: An 11-year-old boy has been charged with manslaughter over the fatal sh...\n",
      "the max_value of column target is 0\n"
     ]
    }
   ],
   "source": [
    "my_fill_na_function(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a function that replaces the non alpha characters from the strings in the database befor next steps\n",
    "\n",
    "def my_remove_nonalpha(dataset):\n",
    "    for my_col in ['keyword','location','text']:\n",
    "        my_pattern=re.compile('[^A-Za-z]+')\n",
    "        dataset[my_col]=[my_pattern.sub(' ',my_text) for my_text in dataset[my_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_remove_nonalpha(data_train)\n",
    "my_remove_nonalpha(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10876, 6)\n",
      "Index(['index', 'id', 'keyword', 'location', 'target', 'text'], dtype='object')\n",
      "\n",
      "\n",
      "index          0\n",
      "id             0\n",
      "keyword        0\n",
      "location       0\n",
      "target      3263\n",
      "text           0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeanm\\Anaconda3\\envs\\test\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# we concatenate horizonatally the 2 databases\n",
    "my_data_all=pd.concat([data_train,data_test], axis=0).reset_index()\n",
    "data_set_exploration(my_data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>fatalities</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>fatalities</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Forest fire near La Ronge Sask Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>fatalities</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>All residents asked to shelter in place are be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>fatalities</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>people receive wildfires evacuation orders in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>fatalities</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  id     keyword location  target  \\\n",
       "0      0   1  fatalities      USA     1.0   \n",
       "1      1   4  fatalities      USA     1.0   \n",
       "2      2   5  fatalities      USA     1.0   \n",
       "3      3   6  fatalities      USA     1.0   \n",
       "4      4   7  fatalities      USA     1.0   \n",
       "\n",
       "                                                text  \n",
       "0  Our Deeds are the Reason of this earthquake Ma...  \n",
       "1              Forest fire near La Ronge Sask Canada  \n",
       "2  All residents asked to shelter in place are be...  \n",
       "3   people receive wildfires evacuation orders in...  \n",
       "4  Just got sent this photo from Ruby Alaska as s...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7613</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>deluged</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7614</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>deluged</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about earthquake is different cities sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7615</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>deluged</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond geese are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7616</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>deluged</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting Spokane wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7617</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>deluged</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  id  keyword  location  target  \\\n",
       "7613      0   0  deluged  New York     NaN   \n",
       "7614      1   2  deluged  New York     NaN   \n",
       "7615      2   3  deluged  New York     NaN   \n",
       "7616      3   9  deluged  New York     NaN   \n",
       "7617      4  11  deluged  New York     NaN   \n",
       "\n",
       "                                                   text  \n",
       "7613                 Just happened a terrible car crash  \n",
       "7614  Heard about earthquake is different cities sta...  \n",
       "7615  there is a forest fire at spot pond geese are ...  \n",
       "7616              Apocalypse lighting Spokane wildfires  \n",
       "7617         Typhoon Soudelor kills in China and Taiwan  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data_all[my_data_all['target'].isna()==True].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step4: start the NLP transformation of the database content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# we are going to tokenize and stem the 'keyword' columns of the test and train datasets merge in my_data_all\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "#from nltk.stem import PorterStemmer\n",
    "#porter=PorterStemmer()\n",
    "lemma = WordNetLemmatizer()\n",
    "keyword_split=[my_keyword.split() for my_keyword in my_data_all['keyword']]\n",
    "new_keyword_split=pd.DataFrame(keyword_split)\n",
    "\n",
    "my_row_max=new_keyword_split.shape[0]\n",
    "my_col_max=new_keyword_split.shape[1]\n",
    "my_count=0\n",
    "for my_col in range(my_col_max):\n",
    "    new_keyword_split.iloc[:,my_col].astype(str)\n",
    "    for my_row in range(my_row_max):\n",
    "        if new_keyword_split.iloc[my_row,my_col] is not None:\n",
    "            try: \n",
    "                new_keyword_split.iloc[my_row,my_col]=lemma.lemmatize(new_keyword_split.iloc[my_row,my_col])\n",
    "            except: \n",
    "                my_count+=1\n",
    "print(my_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fatality      161\n",
       "emergency     150\n",
       "body          150\n",
       "suicide       150\n",
       "building      100\n",
       "             ... \n",
       "rescue         33\n",
       "threat         16\n",
       "inundation     14\n",
       "radiation      14\n",
       "epicentre      13\n",
       "Name: 0, Length: 201, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we now have a reduced amount of keywords that have been stemmed and split into 4 columns\n",
    "new_keyword_split.iloc[:,0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_keyword_split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fatality               161\n",
       "weapon                 100\n",
       "injury                 100\n",
       "siren                  100\n",
       "body bag               100\n",
       "                      ... \n",
       "battle                  33\n",
       "threat                  16\n",
       "radiation emergency     14\n",
       "inundation              14\n",
       "epicentre               13\n",
       "Name: final_kw, Length: 211, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we join the 4 columns in one sole column\n",
    "new_keyword_split['final_kw']=new_keyword_split.iloc[:,0:3].apply(lambda x: None if x.isnull().all() else ' '.join(x.dropna()), axis=1)\n",
    "\n",
    "# we only keep the first column\n",
    "my_new_keyword=new_keyword_split['final_kw']\n",
    "\n",
    "#how many individual items?: 166\n",
    "my_new_keyword.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# we are going to tokenize and stem the 'text' columns of the test and train datasets merge in my_data_all\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "#from nltk.stem import PorterStemmer\n",
    "#porter=PorterStemmer()\n",
    "lemma = WordNetLemmatizer()\n",
    "text_split=[my_text.split() for my_text in my_data_all['text']]\n",
    "new_text_split=pd.DataFrame(text_split)\n",
    "\n",
    "my_row_max=new_text_split.shape[0]\n",
    "my_col_max=new_text_split.shape[1]\n",
    "my_count=0\n",
    "for my_col in range(my_col_max):\n",
    "    new_text_split.iloc[:,my_col].astype(str)\n",
    "    for my_row in range(my_row_max):\n",
    "        if new_text_split.iloc[my_row,my_col] is not None:\n",
    "            try: \n",
    "                new_text_split.iloc[my_row,my_col]=lemma.lemmatize(new_text_split.iloc[my_row,my_col])\n",
    "            except: \n",
    "                my_count+=1\n",
    "print(my_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876, 33)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text_split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we join all the columns in one sole column\n",
    "new_text_split['final_text']=new_text_split.apply(lambda x: None if x.isnull().all() else ' '.join(x.dropna()), axis=1)\n",
    "\n",
    "# we only keep the first column\n",
    "my_new_text=new_text_split['final_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Our Deeds are the Reason of this earthquake Ma...\n",
       "1                Forest fire near La Ronge Sask Canada\n",
       "2    All resident asked to shelter in place are bei...\n",
       "3    people receive wildfire evacuation order in Ca...\n",
       "4    Just got sent this photo from Ruby Alaska a sm...\n",
       "Name: final_text, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_new_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Heard about earthquake is different city stay safe everyone'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_new_text[7614]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_new_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we create the new dataframe\n",
    "my_data_all.loc[:,'new_kw']=my_new_keyword\n",
    "my_data_all.loc[:,'new_text']=my_new_text\n",
    "my_data_all=my_data_all.drop(['keyword','text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>target</th>\n",
       "      <th>new_kw</th>\n",
       "      <th>new_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fatality</td>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fatality</td>\n",
       "      <td>Forest fire near La Ronge Sask Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fatality</td>\n",
       "      <td>All resident asked to shelter in place are bei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fatality</td>\n",
       "      <td>people receive wildfire evacuation order in Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fatality</td>\n",
       "      <td>Just got sent this photo from Ruby Alaska a sm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  id location  target    new_kw  \\\n",
       "0      0   1      USA     1.0  fatality   \n",
       "1      1   4      USA     1.0  fatality   \n",
       "2      2   5      USA     1.0  fatality   \n",
       "3      3   6      USA     1.0  fatality   \n",
       "4      4   7      USA     1.0  fatality   \n",
       "\n",
       "                                            new_text  \n",
       "0  Our Deeds are the Reason of this earthquake Ma...  \n",
       "1              Forest fire near La Ronge Sask Canada  \n",
       "2  All resident asked to shelter in place are bei...  \n",
       "3  people receive wildfire evacuation order in Ca...  \n",
       "4  Just got sent this photo from Ruby Alaska a sm...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>target</th>\n",
       "      <th>new_kw</th>\n",
       "      <th>new_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7613</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deluged</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7614</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deluged</td>\n",
       "      <td>Heard about earthquake is different city stay ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7615</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deluged</td>\n",
       "      <td>there is a forest fire at spot pond goose are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7616</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deluged</td>\n",
       "      <td>Apocalypse lighting Spokane wildfire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7617</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deluged</td>\n",
       "      <td>Typhoon Soudelor kill in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  id  location  target   new_kw  \\\n",
       "7613      0   0  New York     NaN  deluged   \n",
       "7614      1   2  New York     NaN  deluged   \n",
       "7615      2   3  New York     NaN  deluged   \n",
       "7616      3   9  New York     NaN  deluged   \n",
       "7617      4  11  New York     NaN  deluged   \n",
       "\n",
       "                                               new_text  \n",
       "7613                 Just happened a terrible car crash  \n",
       "7614  Heard about earthquake is different city stay ...  \n",
       "7615  there is a forest fire at spot pond goose are ...  \n",
       "7616               Apocalypse lighting Spokane wildfire  \n",
       "7617          Typhoon Soudelor kill in China and Taiwan  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data_all[my_data_all['target'].isna()==True].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we save the tokenized and stemmed database\n",
    "my_data_all.to_csv('./my_data_all_lemma.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we load back the database\n",
    "my_data_all_clean=pd.read_csv('./my_data_all_lemma.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>target</th>\n",
       "      <th>new_kw</th>\n",
       "      <th>new_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fatality</td>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fatality</td>\n",
       "      <td>Forest fire near La Ronge Sask Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fatality</td>\n",
       "      <td>All resident asked to shelter in place are bei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fatality</td>\n",
       "      <td>people receive wildfire evacuation order in Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fatality</td>\n",
       "      <td>Just got sent this photo from Ruby Alaska a sm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  id location  target    new_kw  \\\n",
       "0      0   1      USA     1.0  fatality   \n",
       "1      1   4      USA     1.0  fatality   \n",
       "2      2   5      USA     1.0  fatality   \n",
       "3      3   6      USA     1.0  fatality   \n",
       "4      4   7      USA     1.0  fatality   \n",
       "\n",
       "                                            new_text  \n",
       "0  Our Deeds are the Reason of this earthquake Ma...  \n",
       "1              Forest fire near La Ronge Sask Canada  \n",
       "2  All resident asked to shelter in place are bei...  \n",
       "3  people receive wildfire evacuation order in Ca...  \n",
       "4  Just got sent this photo from Ruby Alaska a sm...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data_all_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>target</th>\n",
       "      <th>new_kw</th>\n",
       "      <th>new_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7613</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deluged</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7614</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deluged</td>\n",
       "      <td>Heard about earthquake is different city stay ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7615</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deluged</td>\n",
       "      <td>there is a forest fire at spot pond goose are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7616</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deluged</td>\n",
       "      <td>Apocalypse lighting Spokane wildfire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7617</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deluged</td>\n",
       "      <td>Typhoon Soudelor kill in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  id  location  target   new_kw  \\\n",
       "7613      0   0  New York     NaN  deluged   \n",
       "7614      1   2  New York     NaN  deluged   \n",
       "7615      2   3  New York     NaN  deluged   \n",
       "7616      3   9  New York     NaN  deluged   \n",
       "7617      4  11  New York     NaN  deluged   \n",
       "\n",
       "                                               new_text  \n",
       "7613                 Just happened a terrible car crash  \n",
       "7614  Heard about earthquake is different city stay ...  \n",
       "7615  there is a forest fire at spot pond goose are ...  \n",
       "7616               Apocalypse lighting Spokane wildfire  \n",
       "7617          Typhoon Soudelor kill in China and Taiwan  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data_all_clean[my_data_all_clean['target'].isna()==True].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_data_all_clean[\"new_text\"]=[my_text.lower() for my_text in my_data_all_clean[\"new_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>target</th>\n",
       "      <th>new_kw</th>\n",
       "      <th>new_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fatality</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fatality</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fatality</td>\n",
       "      <td>all resident asked to shelter in place are bei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fatality</td>\n",
       "      <td>people receive wildfire evacuation order in ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fatality</td>\n",
       "      <td>just got sent this photo from ruby alaska a sm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  id location  target    new_kw  \\\n",
       "0      0   1      USA     1.0  fatality   \n",
       "1      1   4      USA     1.0  fatality   \n",
       "2      2   5      USA     1.0  fatality   \n",
       "3      3   6      USA     1.0  fatality   \n",
       "4      4   7      USA     1.0  fatality   \n",
       "\n",
       "                                            new_text  \n",
       "0  our deeds are the reason of this earthquake ma...  \n",
       "1              forest fire near la ronge sask canada  \n",
       "2  all resident asked to shelter in place are bei...  \n",
       "3  people receive wildfire evacuation order in ca...  \n",
       "4  just got sent this photo from ruby alaska a sm...  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data_all_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a function that build new features from a text string\n",
    "def string_features(my_string):\n",
    "    my_length = len(my_string)\n",
    "    my_words = len(my_string.split())\n",
    "    largest_word=len(max(my_string.split(),key=len))\n",
    "    mean_word_size=round(my_length/my_words,0)\n",
    "    return (my_length, my_words, largest_word,mean_word_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_all_clean[\"my_length\"]=[string_features(my_string)[0] for my_string in my_data_all_clean[\"new_text\"]]\n",
    "my_data_all_clean[\"word_counts\"]=[string_features(my_string)[1] for my_string in my_data_all_clean[\"new_text\"]]\n",
    "my_data_all_clean[\"largest_word\"]=[string_features(my_string)[2] for my_string in my_data_all_clean[\"new_text\"]]\n",
    "my_data_all_clean[\"mean_word_size\"]=[string_features(my_string)[3] for my_string in my_data_all_clean[\"new_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>target</th>\n",
       "      <th>new_kw</th>\n",
       "      <th>new_text</th>\n",
       "      <th>my_length</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>largest_word</th>\n",
       "      <th>mean_word_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fatality</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>67</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fatality</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fatality</td>\n",
       "      <td>all resident asked to shelter in place are bei...</td>\n",
       "      <td>127</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fatality</td>\n",
       "      <td>people receive wildfire evacuation order in ca...</td>\n",
       "      <td>54</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>USA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fatality</td>\n",
       "      <td>just got sent this photo from ruby alaska a sm...</td>\n",
       "      <td>83</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  id location  target    new_kw  \\\n",
       "0      0   1      USA     1.0  fatality   \n",
       "1      1   4      USA     1.0  fatality   \n",
       "2      2   5      USA     1.0  fatality   \n",
       "3      3   6      USA     1.0  fatality   \n",
       "4      4   7      USA     1.0  fatality   \n",
       "\n",
       "                                            new_text  my_length  word_counts  \\\n",
       "0  our deeds are the reason of this earthquake ma...         67           13   \n",
       "1              forest fire near la ronge sask canada         37            7   \n",
       "2  all resident asked to shelter in place are bei...        127           22   \n",
       "3  people receive wildfire evacuation order in ca...         54            7   \n",
       "4  just got sent this photo from ruby alaska a sm...         83           16   \n",
       "\n",
       "   largest_word  mean_word_size  \n",
       "0            10             5.0  \n",
       "1             6             5.0  \n",
       "2            10             6.0  \n",
       "3            10             8.0  \n",
       "4             8             5.0  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data_all_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we create back the train and test databases\n",
    "my_train_data_clean=my_data_all_clean.dropna(axis=0, subset=['target'])\n",
    "my_test_data_clean=my_data_all_clean[my_data_all_clean['target'].isna()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of stop words\n",
    "stoplist = set('for a of the and to in to be which some is at that we i who whom show via may my our might as well'.split())\n",
    "\n",
    "# we create a function that vectorizes the text of the targetted text data (fit_transform of train, transform of test)\n",
    "# and returns the concatenation of both\n",
    "def text_vectorizer(train_series, test_series):\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words=stoplist, min_df=0.001, max_df=0.9)\n",
    "    return pd.concat([pd.DataFrame(tfidf_vectorizer.fit_transform(train_series).toarray()),pd.DataFrame(tfidf_vectorizer.transform(test_series).toarray())],axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_keyword=text_vectorizer(my_train_data_clean['new_kw'], my_test_data_clean['new_kw'])\n",
    "tfidf_text=text_vectorizer(my_train_data_clean['new_text'], my_test_data_clean['new_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#my_column_kw=[]\n",
    "#for my_kw_index in range(tfidf_keyword.shape[1]):\n",
    "#    my_column_kw.append('kw_'+str(my_kw_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_column_text=[]\n",
    "for my_text_index in range(tfidf_text.shape[1]-1):\n",
    "    my_column_text.append('text_'+str(my_text_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_column=['id','target','my_lengths','word_counts','largest_word','mean_word_size']+my_column_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1817"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we remove the text, location and keyword columns from the train and test databases and replace by the tfidf columns\n",
    "\n",
    "my_new_data_all = pd.concat([my_data_all_clean,tfidf_text], axis=1)\n",
    "#my_new_data_all = pd.concat([my_new_data_all,tfidf_text], axis=1, join='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                              0\n",
       "id                                                 0\n",
       "location                                    New York\n",
       "target                                           NaN\n",
       "new_kw                                       deluged\n",
       "new_text          just happened a terrible car crash\n",
       "my_length                                         34\n",
       "word_counts                                        6\n",
       "largest_word                                       8\n",
       "mean_word_size                                     6\n",
       "Name: 7613, dtype: object"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_new_data_all.iloc[7613,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we add a lebellized location column\n",
    "#my_new_data_all['encoded_location']=my_new_data_all['location'].astype('category').cat.codes\n",
    "# my_new_data_all=my_new_data_all.drop('keyword', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([         'index',             'id',       'location',         'target',\n",
       "               'new_kw',       'new_text',      'my_length',    'word_counts',\n",
       "         'largest_word', 'mean_word_size',\n",
       "       ...\n",
       "                   1801,             1802,             1803,             1804,\n",
       "                   1805,             1806,             1807,             1808,\n",
       "                   1809,             1810],\n",
       "      dtype='object', length=1822)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_new_data_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_data_all=my_new_data_all.drop(['index','new_kw','location','new_text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876, 1817)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_new_data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#we set the new columns to the my_new_data_all\n",
    "my_new_data_all.columns=my_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#my_new_data_all['encoded_location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>my_lengths</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>largest_word</th>\n",
       "      <th>mean_word_size</th>\n",
       "      <th>text_0</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>text_3</th>\n",
       "      <th>...</th>\n",
       "      <th>text_1801</th>\n",
       "      <th>text_1802</th>\n",
       "      <th>text_1803</th>\n",
       "      <th>text_1804</th>\n",
       "      <th>text_1805</th>\n",
       "      <th>text_1806</th>\n",
       "      <th>text_1807</th>\n",
       "      <th>text_1808</th>\n",
       "      <th>text_1809</th>\n",
       "      <th>text_1810</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>127</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1817 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target  my_lengths  word_counts  largest_word  mean_word_size  text_0  \\\n",
       "0   1     1.0          67           13            10             5.0     0.0   \n",
       "1   4     1.0          37            7             6             5.0     0.0   \n",
       "2   5     1.0         127           22            10             6.0     0.0   \n",
       "3   6     1.0          54            7            10             8.0     0.0   \n",
       "4   7     1.0          83           16             8             5.0     0.0   \n",
       "\n",
       "   text_1  text_2  text_3  ...  text_1801  text_1802  text_1803  text_1804  \\\n",
       "0     0.0     0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "1     0.0     0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "2     0.0     0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "3     0.0     0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "4     0.0     0.0     0.0  ...        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   text_1805  text_1806  text_1807  text_1808  text_1809  text_1810  \n",
       "0        0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "1        0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "2        0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "3        0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "4        0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "\n",
       "[5 rows x 1817 columns]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_new_data_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step5: we train a classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7460, 1815) (153, 1815)\n"
     ]
    }
   ],
   "source": [
    "# first we split the train database into some train and test points with split function\n",
    "my_new_train_data=my_new_data_all.dropna(axis=0, subset=['target'])\n",
    "my_y=my_new_train_data['target']\n",
    "my_X=my_new_train_data.drop(['id','target'], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "X_scale=scaler.fit_transform(my_X.values)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scale,my_y, random_state=51,test_size=.02)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC Score:   0.810\n"
     ]
    }
   ],
   "source": [
    "# then, we create a LinearSVM model\n",
    "tfidf_tweet_svc = LinearSVC(penalty='l2', dual=False, max_iter=20000, tol=0.00001, C=0.07).fit(X_train,y_train)\n",
    "# we run predict on the X_test to get predictions\n",
    "tfidf_tweet_svc_pred = tfidf_tweet_svc.predict(X_test)\n",
    "# we Calculate accuracy using the metrics module\n",
    "tfidf_tweet_svc_score = metrics.accuracy_score(y_test,tfidf_tweet_svc_pred)\n",
    "print(\"LinearSVC Score:   %0.3f\" % tfidf_tweet_svc_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Score:   0.798\n",
      "Logistic regression Score:   0.798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeanm\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoost Score:   0.769\n",
      "RandomForest Score:   0.774\n"
     ]
    }
   ],
   "source": [
    "# then, we create a NaiveBaies classifier model\n",
    "tfidf_tweet_nb = MultinomialNB(alpha=1).fit(X_train,y_train)\n",
    "# we run predict on the X_test to get predictions\n",
    "tfidf_tweet_nb_pred = tfidf_tweet_nb.predict(X_test)\n",
    "# we Calculate accuracy using the metrics module\n",
    "tfidf_tweet_nb_score = metrics.accuracy_score(y_test,tfidf_tweet_nb_pred)\n",
    "print(\"MultinomialNB Score:   %0.3f\" % tfidf_tweet_nb_score)\n",
    "\n",
    "# then, we create a logistic regression classifier model\n",
    "tfidf_tweet_lr = LogisticRegression().fit(X_train,y_train)\n",
    "# we run predict on the X_test to get predictions\n",
    "tfidf_tweet_lr_pred = tfidf_tweet_lr.predict(X_test)\n",
    "# we Calculate accuracy using the metrics module\n",
    "tfidf_tweet_lr_score = metrics.accuracy_score(y_test,tfidf_tweet_lr_pred)\n",
    "print(\"Logistic regression Score:   %0.3f\" % tfidf_tweet_nb_score)\n",
    "\n",
    "#then, # then, we create a gradient boost classifier model\n",
    "tfidf_tweet_gb = GradientBoostingClassifier(n_estimators=100, random_state=2018).fit(X_train,y_train)\n",
    "# we run predict on the X_test to get predictions\n",
    "tfidf_tweet_gb_pred = tfidf_tweet_gb.predict(X_test)\n",
    "# we Calculate accuracy using the metrics module\n",
    "tfidf_tweet_gb_score = metrics.accuracy_score(y_test,tfidf_tweet_gb_pred)\n",
    "print(\"GradientBoost Score:   %0.3f\" % tfidf_tweet_gb_score)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, max_depth=20,min_samples_split=2,random_state=2012)\n",
    "#then, # then, we create a randomforest classifier model\n",
    "tfidf_tweet_rf = rf.fit(X_train,y_train)\n",
    "# we run predict on the X_test to get predictions\n",
    "tfidf_tweet_rf_pred = tfidf_tweet_rf.predict(X_test)\n",
    "# we Calculate accuracy using the metrics module\n",
    "tfidf_tweet_rf_score = metrics.accuracy_score(y_test,tfidf_tweet_rf_pred)\n",
    "print(\"RandomForest Score:   %0.3f\" % tfidf_tweet_rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVC works best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step6: we save the predicted results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeanm\\Anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "final_X_test=my_new_data_all[my_new_data_all['target'].isna()==True]\n",
    "my_X=final_X_test.drop(['id','target'], axis=1)\n",
    "my_X_scale=scaler.transform(my_X.values)\n",
    "final_X_test.loc[:,'target']=tfidf_tweet_svc.predict(my_X_scale)\n",
    "final_X_test=final_X_test.loc[:,('id','target')]\n",
    "final_X_test['id']=final_X_test['id'].astype('int32')\n",
    "final_X_test=final_X_test.set_index('id')\n",
    "final_X_test['target']=final_X_test['target'].astype('int32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_X_test.to_csv('./NLP_submission_JM_6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#why does the new workflow gives so shitty predictions on the test sample while giving excellent train/test results on the train dataset ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step7: understanding the differences in predictions on the test matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_2=pd.read_csv('./NLP_submission_JM_2.csv')\n",
    "sub_3=pd.read_csv('./NLP_submission_JM_3.csv')\n",
    "sub_4=pd.read_csv('./NLP_submission_JM_4.csv')\n",
    "sub_5=pd.read_csv('./NLP_submission_JM_5.csv')\n",
    "sub_6=pd.read_csv('./NLP_submission_JM_6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2104\n",
      "1    1159\n",
      "Name: target, dtype: int64\n",
      "0    2117\n",
      "1    1146\n",
      "Name: target, dtype: int64\n",
      "0    2172\n",
      "1    1091\n",
      "Name: target, dtype: int64\n",
      "0    2107\n",
      "1    1156\n",
      "Name: target, dtype: int64\n",
      "0    2076\n",
      "1    1187\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(sub_2['target'].value_counts())\n",
    "print(sub_3['target'].value_counts())\n",
    "print(sub_4['target'].value_counts())\n",
    "print(sub_5['target'].value_counts())\n",
    "print(sub_6['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compar_vector=[1 if sub_5.iloc[i,1]==sub_6.iloc[i,1] else 0 for i in range(sub_2.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.3"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(sum(compar_vector)/len(compar_vector)*100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
